---
phase: 10-platform-handlers
plan: 04
type: execute
wave: 3
depends_on: ["10-02"]
files_modified:
  - bot/downloaders/platforms/facebook.py
  - bot/downloaders/html_extractor.py
  - bot/downloaders/platforms/__init__.py
  - bot/downloaders/__init__.py
autonomous: true

must_haves:
  truths:
    - "Facebook public videos download successfully"
    - "Facebook Reels are detected and handled correctly"
    - "Generic HTML pages with video tags are parsed"
    - "Video URLs are extracted from HTML and can be downloaded"
  artifacts:
    - path: "bot/downloaders/platforms/facebook.py"
      provides: "Facebook video and Reels downloader"
      exports: ["FacebookDownloader", "is_facebook_url", "is_facebook_reel"]
      min_lines: 180
    - path: "bot/downloaders/html_extractor.py"
      provides: "Generic HTML video extractor"
      exports: ["HTMLVideoExtractor", "extract_videos_from_html"]
      min_lines: 200
  key_links:
    - from: "bot/downloaders/platforms/facebook.py"
      to: "bot/downloaders/ytdlp_downloader.py"
      via: "class inheritance"
      pattern: "class FacebookDownloader(YtDlpDownloader)"
    - from: "bot/downloaders/html_extractor.py"
      to: "bot/downloaders/generic_downloader.py"
      via: "downloads extracted URLs"
      pattern: "GenericDownloader().download()"
---

<objective>
Implement Facebook downloader for public videos and Reels. Also implement a generic HTML video extractor that can parse HTML pages and extract video URLs from video tags, meta tags, and common video player embeds.

Purpose: Complete platform coverage with Facebook (FB-01, FB-02) and enable downloading from any HTML page with embedded videos (GV-02).
Output: FacebookDownloader and HTMLVideoExtractor classes.
</objective>

<execution_context>
@/data/data/com.termux/files/home/.claude/get-shit-done/workflows/execute-plan.md
@/data/data/com.termux/files/home/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@bot/downloaders/ytdlp_downloader.py
@bot/downloaders/generic_downloader.py
@bot/downloaders/base.py
@bot/downloaders/platforms/instagram.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement FacebookDownloader</name>
  <files>bot/downloaders/platforms/facebook.py</files>
  <action>
Create the FacebookDownloader class for Facebook videos and Reels.

Implement:

1. **Facebook URL patterns**:
   ```python
   FACEBOOK_PATTERNS = {
       'video': [
           r'facebook\.com/watch\?v=\d+',
           r'facebook\.com/\w+/videos/\d+',
           r'facebook\.com/video\.php\?v=\d+',
           r'fb\.watch/\w+',
       ],
       'reel': [
           r'facebook\.com/reel/\d+',
           r'facebook\.com/\w+/reels/\d+',
       ],
   }
   ```

2. **Helper functions**:
   ```python
   def is_facebook_url(url: str) -> bool:
       """Check if URL is a Facebook URL."""
       patterns = [
           r'facebook\.com',
           r'fb\.watch',
       ]
       return any(re.search(p, url.lower()) for p in patterns)

   def is_facebook_reel(url: str) -> bool:
       """Check if URL is a Facebook Reel."""
       return '/reel/' in url.lower() or '/reels/' in url.lower()

   def is_facebook_watch(url: str) -> bool:
       """Check if URL is a Facebook Watch video."""
       return '/watch' in url.lower() or '/videos/' in url.lower()

   def extract_facebook_video_id(url: str) -> Optional[str]:
       """Extract Facebook video ID from URL."""
       patterns = [
           r'[?&]v=(\d+)',
           r'/videos/(\d+)',
           r'/reel/(\d+)',
           r'/reels/(\d+)',
           r'fb\.watch/(\w+)',
       ]
       for pattern in patterns:
           match = re.search(pattern, url)
           if match:
               return match.group(1)
       return None
   ```

3. **FacebookDownloader class**:
   ```python
   class FacebookDownloader(YtDlpDownloader):
       """Facebook video and Reels downloader."""

       @property
       def name(self) -> str:
           return "Facebook Downloader"

       @property
       def supported_platforms(self) -> list[str]:
           return ["Facebook", "Facebook Reels"]
   ```

4. **Override can_handle(url: str) -> bool**:
   - Return True if is_facebook_url(url) returns True
   - Validate with super().can_handle()

5. **Override extract_metadata() for Facebook-specific fields**:
   ```python
   async def extract_metadata(self, url: str, options: DownloadOptions) -> dict[str, Any]:
       metadata = await super().extract_metadata(url, options)

       # Add Facebook-specific fields
       info = metadata.get('_raw_info', {})

       metadata['video_id'] = extract_facebook_video_id(url)
       metadata['is_reel'] = is_facebook_reel(url)
       metadata['is_watch'] = is_facebook_watch(url)
       metadata['uploader'] = info.get('uploader')
       metadata['page_name'] = info.get('uploader')
       metadata['description'] = info.get('description', '')

       # Engagement stats (if available)
       metadata['engagement'] = {
           'reactions': info.get('like_count'),
           'comments': info.get('comment_count'),
           'shares': info.get('repost_count'),
       }

       # Facebook videos are usually 16:9 or 9:16 for Reels
       if metadata['is_reel']:
           metadata['aspect_ratio'] = '9:16'
       else:
           metadata['aspect_ratio'] = '16:9'

       return metadata
   ```

6. **Override _build_ydl_options() for Facebook**:
   ```python
   def _build_ydl_options(self, options: DownloadOptions, output_path: str, correlation_id: str) -> dict:
       ydl_opts = super()._build_ydl_options(options, output_path, correlation_id)

       # Facebook-specific options
       # Allow unplayable formats (Facebook sometimes marks videos this way)
       ydl_opts['allow_unplayable_formats'] = False

       # Add headers to avoid blocks
       ydl_opts['http_headers'] = {
           'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
       }

       return ydl_opts
   ```

7. **Error handling**:
   - Handle "Video unavailable" (private or deleted)
   - Handle "Login required" (private videos)
   - Handle "Content not found"
   - Provide clear messages:
     - Private: "Este video de Facebook es privado. Solo puedo descargar videos públicos."
     - Deleted: "Este video no está disponible o ha sido eliminado."
     - Login required: "Este video requiere inicio de sesión. No puedo acceder a contenido privado."

Example metadata:
```python
{
    'title': 'Video by Page Name',
    'duration': 120,
    'uploader': 'Page Name',
    'thumbnail': 'https://scontent-ams2-1.xx.fbcdn.net/...',
    'filesize': 20971520,
    'video_id': '1234567890',
    'is_reel': False,
    'is_watch': True,
    'page_name': 'Page Name',
    'description': 'Video description...',
    'engagement': {
        'reactions': 1000,
        'comments': 50,
        'shares': 100,
    },
    'aspect_ratio': '16:9',
}
```
  </action>
  <verify>
    - FacebookDownloader can be instantiated
    - is_facebook_url returns True for facebook.com and fb.watch URLs
    - is_facebook_reel returns True for /reel/ URLs
    - extract_facebook_video_id returns video ID
    - Metadata includes page_name, engagement stats
    - Aspect ratio is 9:16 for Reels, 16:9 for regular videos
  </verify>
  <done>
    - FacebookDownloader extends YtDlpDownloader
    - Reel detection working
    - Facebook-specific metadata (page_name, engagement)
    - Aspect ratio hints based on content type
    - Error handling for private/unavailable content
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement HTMLVideoExtractor for generic pages</name>
  <files>bot/downloaders/html_extractor.py</files>
  <action>
Create the HTMLVideoExtractor class that can parse HTML pages and extract video URLs from various sources.

Implement:

1. **HTML parsing imports**:
   ```python
   import re
   from typing import List, Optional, Dict, Any
   from urllib.parse import urljoin, urlparse

   try:
       from bs4 import BeautifulSoup
       HAS_BS4 = True
   except ImportError:
       HAS_BS4 = False

   import aiohttp
   import logging

   logger = logging.getLogger(__name__)
   ```

2. **VideoURL dataclass**:
   ```python
   from dataclasses import dataclass

   @dataclass
   class VideoURL:
       """Represents a video URL found in HTML."""
       url: str
       source: str  # 'video_tag', 'meta_tag', 'og_tag', 'json_ld', etc.
       quality: Optional[str] = None
       mime_type: Optional[str] = None
       label: Optional[str] = None
   ```

3. **HTMLVideoExtractor class**:
   ```python
   class HTMLVideoExtractor:
       """Extract video URLs from HTML pages.

       Supports extraction from:
       - <video> tags (src and <source> children)
       - Open Graph meta tags (og:video)
       - Twitter Card meta tags
       - JSON-LD structured data
       - Common video player embeds (if detectable)
       """

       def __init__(self):
           self.session: Optional[aiohttp.ClientSession] = None

       async def __aenter__(self):
           self.session = aiohttp.ClientSession()
           return self

       async def __aexit__(self, exc_type, exc_val, exc_tb):
           if self.session:
               await self.session.close()
   ```

4. **Main extraction method**:
   ```python
   async def extract_videos(self, url: str) -> List[VideoURL]:
       """Extract all video URLs from an HTML page.

       Args:
           url: The URL of the HTML page to parse

       Returns:
           List of VideoURL objects found on the page
       """
       if not self.session:
           self.session = aiohttp.ClientSession()

       try:
           async with self.session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
               response.raise_for_status()
               html = await response.text()
               base_url = str(response.url)
       except Exception as e:
           logger.error(f"Failed to fetch HTML: {e}")
           return []

       videos = []

       if HAS_BS4:
           videos.extend(self._extract_from_video_tags(html, base_url))
           videos.extend(self._extract_from_meta_tags(html, base_url))
           videos.extend(self._extract_from_json_ld(html, base_url))
       else:
           # Fallback to regex if BeautifulSoup not available
           videos.extend(self._extract_with_regex(html, base_url))

       # Deduplicate by URL
       seen = set()
       unique_videos = []
       for v in videos:
           if v.url not in seen:
               seen.add(v.url)
               unique_videos.append(v)

       return unique_videos
   ```

5. **BeautifulSoup extraction methods**:
   ```python
   def _extract_from_video_tags(self, html: str, base_url: str) -> List[VideoURL]:
       """Extract from HTML5 <video> tags."""
       videos = []
       soup = BeautifulSoup(html, 'html.parser')

       for video in soup.find_all('video'):
           # Check src attribute
           src = video.get('src')
           if src:
               videos.append(VideoURL(
                   url=urljoin(base_url, src),
                   source='video_tag',
                   mime_type=video.get('type'),
               ))

           # Check <source> children
           for source in video.find_all('source'):
               src = source.get('src')
               if src:
                   videos.append(VideoURL(
                       url=urljoin(base_url, src),
                       source='video_source_tag',
                       mime_type=source.get('type'),
                       quality=source.get('label') or source.get('res'),
                   ))

       return videos

   def _extract_from_meta_tags(self, html: str, base_url: str) -> List[VideoURL]:
       """Extract from Open Graph and Twitter Card meta tags."""
       videos = []
       soup = BeautifulSoup(html, 'html.parser')

       # Open Graph video tags
       og_video_tags = [
           'og:video',
           'og:video:url',
           'og:video:secure_url',
       ]

       for tag in og_video_tags:
           meta = soup.find('meta', property=tag)
           if meta and meta.get('content'):
               videos.append(VideoURL(
                   url=urljoin(base_url, meta['content']),
                   source='og_meta_tag',
                   mime_type=meta.get('type'),
               ))

       # Twitter Card video
       twitter_video = soup.find('meta', attrs={'name': 'twitter:player'})
       if twitter_video and twitter_video.get('content'):
           videos.append(VideoURL(
               url=urljoin(base_url, twitter_video['content']),
               source='twitter_card',
           ))

       return videos

   def _extract_from_json_ld(self, html: str, base_url: str) -> List[VideoURL]:
       """Extract from JSON-LD structured data."""
       videos = []
       soup = BeautifulSoup(html, 'html.parser')

       for script in soup.find_all('script', type='application/ld+json'):
           try:
               import json
               data = json.loads(script.string)

               # Handle VideoObject
               if isinstance(data, dict) and data.get('@type') == 'VideoObject':
                   content_url = data.get('contentUrl')
                   embed_url = data.get('embedUrl')

                   if content_url:
                       videos.append(VideoURL(
                           url=urljoin(base_url, content_url),
                           source='json_ld',
                           mime_type=data.get('encodingFormat'),
                       ))

                   if embed_url:
                       videos.append(VideoURL(
                           url=urljoin(base_url, embed_url),
                           source='json_ld_embed',
                       ))

               # Handle arrays of objects
               if isinstance(data, list):
                   for item in data:
                       if item.get('@type') == 'VideoObject':
                           content_url = item.get('contentUrl')
                           if content_url:
                               videos.append(VideoURL(
                                   url=urljoin(base_url, content_url),
                                   source='json_ld',
                                   mime_type=item.get('encodingFormat'),
                               ))
           except Exception as e:
               logger.debug(f"Failed to parse JSON-LD: {e}")
               continue

       return videos
   ```

6. **Regex fallback**:
   ```python
   def _extract_with_regex(self, html: str, base_url: str) -> List[VideoURL]:
       """Fallback extraction using regex (no BeautifulSoup)."""
       videos = []

       # Video src patterns
       patterns = [
           r'<video[^>]+src=["\']([^"\']+)["\']',
           r'<source[^>]+src=["\']([^"\']+)["\']',
           r'<meta[^>]+property=["\']og:video["\'][^>]+content=["\']([^"\']+)["\']',
           r'<meta[^>]+property=["\']og:video:url["\'][^>]+content=["\']([^"\']+)["\']',
           r'"contentUrl"\s*:\s*"([^"]+)"',  # JSON-LD
       ]

       for pattern in patterns:
           matches = re.findall(pattern, html, re.IGNORECASE)
           for match in matches:
               if match.startswith('http'):
                   videos.append(VideoURL(
                       url=urljoin(base_url, match),
                       source='regex_fallback',
                   ))

       return videos
   ```

7. **Convenience function**:
   ```python
   async def extract_videos_from_html(url: str) -> List[VideoURL]:
       """Convenience function to extract videos from HTML.

       Args:
           url: URL of the HTML page

       Returns:
           List of VideoURL objects
       """
       async with HTMLVideoExtractor() as extractor:
           return await extractor.extract_videos(url)
   ```

8. **Integration with GenericDownloader**:
   ```python
   async def download_from_html(
       url: str,
       options: DownloadOptions,
       downloader: Optional[GenericDownloader] = None
   ) -> Any:
       """Extract and download first video from HTML page.

       Args:
           url: HTML page URL
           options: Download options
           downloader: GenericDownloader instance (creates if None)

       Returns:
           DownloadResult from the first successfully downloaded video
       """
       from .. import DownloadResult
       from .generic_downloader import GenericDownloader

       videos = await extract_videos_from_html(url)

       if not videos:
           return DownloadResult(
               success=False,
               error_message="No videos found on the page",
           )

       if downloader is None:
           downloader = GenericDownloader()

       # Try each video URL until one succeeds
       for video in videos:
           try:
               result = await downloader.download(video.url, options)
               if result.success:
                   return result
           except Exception as e:
               logger.debug(f"Failed to download {video.url}: {e}")
               continue

       return DownloadResult(
           success=False,
           error_message="Failed to download any video from the page",
       )
   ```
  </action>
  <verify>
    - HTMLVideoExtractor can be instantiated
    - extract_videos returns list of VideoURL objects
    - Video tag extraction works
    - Meta tag extraction works
    - JSON-LD extraction works
    - Regex fallback works without BeautifulSoup
    - download_from_html integrates with GenericDownloader
  </verify>
  <done>
    - HTMLVideoExtractor class implemented
    - Extraction from video tags, meta tags, JSON-LD
    - BeautifulSoup and regex fallback support
    - VideoURL dataclass for structured results
    - Integration function download_from_html
  </done>
</task>

<task type="auto">
  <name>Task 3: Update package exports</name>
  <files>bot/downloaders/platforms/__init__.py, bot/downloaders/__init__.py, bot/downloaders/html_extractor.py</files>
  <action>
Update package exports to include Facebook downloader and HTML extractor.

1. Update bot/downloaders/platforms/__init__.py:
```python
from .facebook import (
    FacebookDownloader,
    is_facebook_url,
    is_facebook_reel,
    extract_facebook_video_id,
)

__all__ = [
    # YouTube
    'YouTubeDownloader',
    'is_youtube_url',
    'is_youtube_shorts',
    # Instagram
    'InstagramDownloader',
    'InstagramContentType',
    'detect_instagram_content_type',
    'is_instagram_reel',
    'is_instagram_story',
    'is_instagram_url',
    'extract_shortcode',
    # TikTok
    'TikTokDownloader',
    'is_tiktok_url',
    'is_tiktok_slideshow',
    'extract_tiktok_id',
    # Twitter/X
    'TwitterDownloader',
    'is_twitter_url',
    'extract_tweet_id',
    'extract_username',
    # Facebook
    'FacebookDownloader',
    'is_facebook_url',
    'is_facebook_reel',
    'extract_facebook_video_id',
]
```

2. Create/update bot/downloaders/html_extractor.py with exports:
```python
__all__ = [
    'VideoURL',
    'HTMLVideoExtractor',
    'extract_videos_from_html',
    'download_from_html',
]
```

3. Update bot/downloaders/__init__.py:
```python
# Import platform handlers
from .platforms import (
    # YouTube
    YouTubeDownloader,
    is_youtube_shorts,
    is_youtube_url,
    # Instagram
    InstagramDownloader,
    InstagramContentType,
    is_instagram_reel,
    is_instagram_story,
    # TikTok
    TikTokDownloader,
    is_tiktok_url,
    is_tiktok_slideshow,
    # Twitter/X
    TwitterDownloader,
    is_twitter_url,
    # Facebook
    FacebookDownloader,
    is_facebook_url,
    is_facebook_reel,
)

# Import HTML extractor
from .html_extractor import (
    HTMLVideoExtractor,
    VideoURL,
    extract_videos_from_html,
    download_from_html,
)

# Add to __all__
__all__ = [
    # ... existing exports ...
    # Platform handlers
    'YouTubeDownloader',
    'is_youtube_shorts',
    'is_youtube_url',
    'InstagramDownloader',
    'InstagramContentType',
    'is_instagram_reel',
    'is_instagram_story',
    'TikTokDownloader',
    'is_tiktok_url',
    'is_tiktok_slideshow',
    'TwitterDownloader',
    'is_twitter_url',
    'FacebookDownloader',
    'is_facebook_url',
    'is_facebook_reel',
    # HTML extractor
    'HTMLVideoExtractor',
    'VideoURL',
    'extract_videos_from_html',
    'download_from_html',
]
```

4. Add beautifulsoup4 to requirements.txt (optional dependency):
```
# Optional for HTML video extraction
beautifulsoup4>=4.12.0
```
  </action>
  <verify>
    - FacebookDownloader is importable from bot.downloaders
    - HTMLVideoExtractor is importable from bot.downloaders
    - VideoURL dataclass is exportable
    - Helper functions are available
    - No circular import errors
  </verify>
  <done>
    - Facebook handler exported
    - HTML extractor exported
    - All helper functions available
    - beautifulsoup4 added as optional dependency
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. **Import tests**:
   - `python -c "from bot.downloaders import FacebookDownloader; print('OK')"`
   - `python -c "from bot.downloaders import HTMLVideoExtractor; print('OK')"`
2. **Facebook URL detection**: Test is_facebook_url and is_facebook_reel
3. **HTML extraction**: Test extract_videos_from_html with a sample HTML string

Run: `python -c "from bot.downloaders.platforms import FacebookDownloader; from bot.downloaders.html_extractor import HTMLVideoExtractor; print('All OK')"`
</verification>

<success_criteria>
- FacebookDownloader extends YtDlpDownloader correctly
- Facebook Reel detection working
- Facebook metadata includes page_name, engagement stats
- HTMLVideoExtractor can parse video tags
- HTMLVideoExtractor can parse Open Graph meta tags
- HTMLVideoExtractor can parse JSON-LD structured data
- Regex fallback works without BeautifulSoup
- Package exports updated correctly
- No breaking changes to existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/10-platform-handlers/10-04-SUMMARY.md`
</output>
